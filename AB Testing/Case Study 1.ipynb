{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "Generally, rate is used when you want to measure the usability of the site, and probability when you want to measure the impact.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory - https://rpubs.com/superseer/ab_testing\n",
    "1. Binomial Distribution- \n",
    "For a binomial distribution with probability p , the mean is given by p and the standard deviation is p∗(1−p)/N−−−−−−−−−−−√ where N is the number of trials. A binomial distribution can be used when\n",
    "\n",
    "    The outcomes are of 2 types\n",
    "    Each event is independent of the other\n",
    "    Each event has an identical distribution (i.e. p is the same for all)\n",
    "2. Confidence Interval - \n",
    "A confidence interval indicates the range within which the mean is expected to fall in multiple trials of the experiment. For e.g., consider $\\hat(p)$ - the proportion of users that click, where N is the number of users. Let us assume a binomial distribution (this requires $N\\hat(p)>5$ and N(1−\\hat(p))>5). The margin of error is given by\n",
    "$$m=z∗se$$\n",
    "$$ m = z*\\sqrt{\\frac{\\hat{p}.(1-\\hat{p})}{N}}$$\n",
    "For a 95% confidence interval, z = 1.96.\n",
    "\n",
    "3. Hypothesis Testing\n",
    "The null hypothesis states that the difference between the control and experiment is due to chance. If $p_{cont}$ and $p_{test}$ are the control and test probabilities, then according to the null hypothesis\n",
    "$$ H0:p_{exp}−p_{cont}=0 $$\n",
    "\n",
    "The alternate hypothesis is that\n",
    "$$ H1:p_{exp}−p_{cont}≠0 $$\n",
    "\n",
    "4. Comparing two samples\n",
    "For comparing two samples, we calculate the pooled standard error. For e.g., suppose Xcont and Ncont are the control number of users that click, and the total number of users in the control group. Let Xexp and Nexp be the values for the experiment. The pooled probability is given by\n",
    "$$\\hat{p}_{pool}= \\frac{X_{cont}+X_{exp}}{N_{cont}+ N_{test}}$$\n",
    "$$ SE_{pool} = \\sqrt{\\hat{p}_{pool}*(1-\\hat{p}_{pool})*(\\frac{1}{N_{cont}}+\\frac{1}{N_{test}})} $$\n",
    "$$ \\hat{d} =\\hat{p}_{exp}-\\hat{p}_{cont} $$\n",
    "$$ H_0: d = 0  \\text{  where  } \\hat{d} \\sim N(0,SE_{pool})$$\n",
    "If $\\hat{d}>1.96∗SE_{pool}$ or $\\hat{d}<−1.96∗SE_{pool}$ then we can reject the null hypothesis and state that our difference represents a statistically significant difference\n",
    "5. Practical significance\n",
    "Practical significance is the level of change that you would expect to see from a business standpoint for the change to be valuable. What is considered practically significant can vary by field. In medicine, one would expect a 5,10 or 15% improvement for the result to be considered practically significant. At Google, for example, a 1-2% improvement in click through probability is practically significant.\n",
    "\n",
    "The statistical significance bar is often lower than the practical significance bar, so that if the outcome is practically significance, it is also statistically significant.\n",
    "\n",
    "6. Size vs Power trade-off\n",
    "One of the decisions is to determine the number of data points needed to get a statistically significant result. This is called statistical power. Power has an inverse trade-off with size. The smaller the change you want to detect or the increased confidence you want to have in the result, means you have to run a larger experiment.\n",
    "\n",
    "As you increase the number of samples, the confidence interval moves closer to the mean\n",
    "\n",
    "$$\\alpha = P(\\text{reject null | null true})$$\n",
    "$$\\beta = P(\\text{fail to reject null | null false})$$\n",
    "$1−β$ is referred to as the sensitivity of the experiment, or statistical power. People often choose high sensitivity, typically around 80%.\n",
    "\n",
    "For a small sample, α is low and β is high. For a large sample α remains the same but β goes down (i.e. sensitivity increases). A good online calculator for determing the number of samples is here. As you change one of the parameters, your sample size will change as well. For example:\n",
    "\n",
    "    If you increase the baseline click through probability (under 0.5) then this increases the standard error, and therefore, you need a higher number of samples\n",
    "    If you increase the practical significance level, you require a fewer number of samples since larger changes are easier to detect\n",
    "    If you increase the confidence level, you want to be more certain that you are rejecting the null. At the same sensivitiy, this would require increasing the number of samples\n",
    "    If you want to increase the sensitivity, you need to collect more samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028928474040117697"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "N_cont = 10072  # Control samples (pageviews)\n",
    "N_exp = 9886  # Test samples (pageviews)\n",
    "X_cont = 974  # Control clicks\n",
    "X_exp = 1242  # Exp. clicks\n",
    "\n",
    "p_pool = (X_cont + X_exp)/(N_cont+N_exp)\n",
    "se_pool = np.sqrt(p_pool*(1-p_pool)*(1/N_cont + 1/N_exp))\n",
    "\n",
    "p_cont = X_cont/N_cont\n",
    "p_exp = X_exp/N_exp\n",
    "d = p_exp - p_cont\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0087179739320380565"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#95% confidence\n",
    "m = 1.96*se_pool\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020210500108079642"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_min = d-m\n",
    "cf_max = d+m\n",
    "d_min = 0.02 # Minimum practical significance value for difference\n",
    "cf_min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, since the minimum confidence limit is greater than 0 and the practical significance level of 0.02, we conclude that it is highly probable that click through probability is higher than 0.02 and is significant. Based on this, one would launch the new version\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
