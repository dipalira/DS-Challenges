{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import  train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allemp=pd.read_csv(\"all_employees.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert department levels to numbers. As the lower the department the lower their salaries would be. Hence, the initial ranking needs to be present in the numeric. *Same is done for degree_level*\n",
    "* Also, We removed the CEO, as it might act as an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categories to ordered numerics\n",
    "level_types = ['IC','MM',\"D\",\"VP\",\"E\",\"CEO\"]\n",
    "allemp['level_num'] = allemp.level.astype(\"category\",ordered=True,categories=types).cat.codes\n",
    "edu_types = ['High_School','Bachelor','Master','PhD']\n",
    "allemp['degree_num'] = allemp.degree_level.astype(\"category\",ordered=True,categories=edu_types).cat.codes\n",
    "\n",
    "#Removing Ceo\n",
    "allemp = allemp[allemp['level'] != 'CEO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Gender to dummies\n",
    "allemp = pd.get_dummies(allemp, columns=['sex','dept'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>signing_bonus</th>\n",
       "      <th>salary</th>\n",
       "      <th>degree_level</th>\n",
       "      <th>yrs_experience</th>\n",
       "      <th>boss_id</th>\n",
       "      <th>level</th>\n",
       "      <th>n_subordinates</th>\n",
       "      <th>level_num</th>\n",
       "      <th>degree_num</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>dept_HR</th>\n",
       "      <th>dept_engineering</th>\n",
       "      <th>dept_marketing</th>\n",
       "      <th>dept_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138719</td>\n",
       "      <td>0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>Master</td>\n",
       "      <td>2</td>\n",
       "      <td>43602</td>\n",
       "      <td>IC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3192</td>\n",
       "      <td>0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>1</td>\n",
       "      <td>87847</td>\n",
       "      <td>IC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114657</td>\n",
       "      <td>0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>Master</td>\n",
       "      <td>2</td>\n",
       "      <td>180854</td>\n",
       "      <td>IC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29039</td>\n",
       "      <td>0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>High_School</td>\n",
       "      <td>4</td>\n",
       "      <td>88370</td>\n",
       "      <td>IC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118607</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>3</td>\n",
       "      <td>23565</td>\n",
       "      <td>IC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id  signing_bonus  salary degree_level  yrs_experience  boss_id  \\\n",
       "0       138719              0   273.0       Master               2    43602   \n",
       "1         3192              0   301.0     Bachelor               1    87847   \n",
       "2       114657              0   261.0       Master               2   180854   \n",
       "3        29039              0    86.0  High_School               4    88370   \n",
       "4       118607              0   126.0     Bachelor               3    23565   \n",
       "\n",
       "  level  n_subordinates  level_num  degree_num  sex_F  sex_M  dept_HR  \\\n",
       "0    IC               0          0           2      0      1        0   \n",
       "1    IC               0          0           1      1      0        0   \n",
       "2    IC               0          0           2      1      0        0   \n",
       "3    IC               0          0           0      1      0        1   \n",
       "4    IC               0          0           1      1      0        0   \n",
       "\n",
       "   dept_engineering  dept_marketing  dept_sales  \n",
       "0                 1               0           0  \n",
       "1                 0               0           1  \n",
       "2                 0               0           1  \n",
       "3                 0               0           0  \n",
       "4                 0               0           1  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2296b002748>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGAdJREFUeJzt3X+wnXV94PF3yEWkWk3hCOYm2QZK\nFnWcgsoAla6LRFtAhuCOfNS1GDBrdqbg6uhuRVfL7mzbDW5XyOw6tOFHTRxq+CxKybSsWyfIup0V\nFolUWli6kY3kmph4MUQsq/zw7h/P98rh5iTPOTf3PudH3q+ZM+c83/N9zv184OR+7vP9fp/nWTA1\nNYUkSYdyVL8DkCQNPouFJKmWxUKSVMtiIUmqZbGQJNWyWEiSalksJEm1LBaSpFoWC0lSrbF+BzCH\nPBVdkmZnQV2HUSoW7Nq1q98h/Fyr1WJycrLfYcyZUcpnlHKB0cpnlHKB4chnfHy8q34OQ0mSalks\nJEm1LBaSpFoWC0lSLYuFJKmWxUKSVMtiIUmqZbGQJNWyWEiSao3UGdyz9fwHL+7YvvDGLQ1HIkmD\nySMLSVIti4UkqVYjw1ARcSpwW1vTycDvAptK+3JgBxCZuS8iFgDrgQuBp4HLM3NbE7FKkg7UyJFF\nZj6amadn5unAm6gKwB3A1cDWzFwBbC3bABcAK8pjLXBDE3FKkjrrxzDUSuA7mfldYBWwsbRvBC4p\nr1cBmzJzKjPvBRZFxOLmQ5UkQX+KxXuAL5bXJ2bmboDyfEJpXwLsbNtnorRJkvqg0aWzEfES4GLg\nEzVdO9216YA74UXEWqphKjKTVqs1q7j2HKR9tp8HMDY2dlj7D5pRymeUcoHRymeUcoHRyqfp8ywu\nALZl5vTv5z0RsTgzd5dhpr2lfQJY1rbfUuCA2+Bl5gZgQ9mcmus7Uh3O5w3DHbJ6MUr5jFIuMFr5\njFIuMBz5dHunvKaLxXt5YQgKYAuwGlhXnu9sa78qIjYDZwH7p4erJEnNa6xYRMQvAG8H/nlb8zog\nI2IN8DhwaWm/i2rZ7HaqlVNXNBWnJOlAjRWLzHwaOH5G2xNUq6Nm9p0CrmwoNElSDc/gliTVslhI\nkmpZLCRJtSwWkqRaFgtJUi2LhSSplsVCklTL26oegrdblaSKRxaSpFoWC0lSLYuFJKmWxUKSVMti\nIUmqZbGQJNWyWEiSalksJEm1LBaSpFoWC0lSLYuFJKmWxUKSVKuxCwlGxCLgJuD1wBTwAeBR4DZg\nObADiMzcFxELgPXAhcDTwOWZua2pWCVJL9bkkcV64CuZ+RrgNOAR4Gpga2auALaWbYALgBXlsRa4\nocE4JUkzNFIsIuIVwFuAmwEy85nMfBJYBWws3TYCl5TXq4BNmTmVmfcCiyJicROxSpIO1NQw1MnA\nD4A/iYjTgAeADwMnZuZugMzcHREnlP5LgJ1t+0+Utt3tHxoRa6mOPMhMWq3WrILb02P/bn7O2NjY\nrOMZRKOUzyjlAqOVzyjlAqOVT1PFYgx4I/ChzLwvItbzwpBTJws6tE3NbMjMDcCG6fcnJycPO9Bu\ndPNzWq1WV/2GxSjlM0q5wGjlM0q5wHDkMz4+3lW/puYsJoCJzLyvbN9OVTz2TA8vlee9bf2Xte2/\nFNjVUKySpBkaObLIzO9HxM6IODUzHwVWAg+Xx2pgXXm+s+yyBbgqIjYDZwH7p4erBsHBbrcK3nJV\n0mhq8h7cHwJujYiXAI8BV1Ad2WRErAEeBy4tfe+iWja7nWrp7BUNxilJmqGxYpGZDwJndHhrZYe+\nU8CV8x6UJKkrnsEtSaplsZAk1bJYSJJqWSwkSbUsFpKkWhYLSVIti4UkqZbFQpJUy2IhSaplsZAk\n1bJYSJJqWSwkSbUsFpKkWhYLSVIti4UkqZbFQpJUy2IhSaplsZAk1bJYSJJqNXYP7ojYATwFPA88\nl5lnRMRxwG3AcmAHEJm5LyIWAOuBC4Gngcszc1tTsUqSXqzpI4u3ZubpmXlG2b4a2JqZK4CtZRvg\nAmBFeawFbmg4TklSm34PQ60CNpbXG4FL2to3ZeZUZt4LLIqIxf0IUJLUbLGYAv4yIh6IiLWl7cTM\n3A1Qnk8o7UuAnW37TpQ2SVIfNDZnAZyTmbsi4gTgqxHxvw/Rd0GHtqmZDaXorAXITFqt1qwC2zOr\nvTqbjmFsbGzW8QyiUcpnlHKB0cpnlHKB0cqnsWKRmbvK896IuAM4E9gTEYszc3cZZtpbuk8Ay9p2\nXwrs6vCZG4ANZXNqcnJy3uLv1nQMrVaLQYhnroxSPqOUC4xWPqOUCwxHPuPj4131a2QYKiJeFhG/\nOP0a+A3gb4AtwOrSbTVwZ3m9BXh/RCyIiLOB/dPDVZKk5jU1Z3Ei8FcR8dfA/wL+IjO/AqwD3h4R\n/wd4e9kGuAt4DNgO3Aj8dkNxSpI6aGQYKjMfA07r0P4EsLJD+xRwZQOhSZK60O+ls5KkIdB1sYiI\nfxERozGtL0nqSS/DUG8D/iAi7gG+APxZZv50XqKSJA2Uro8sMvNi4JeB/wp8BPh+RNwUEW+Zr+Ak\nSYOhpwnuMiH9OeBzEfGrVEcYV0TETqpVS+sz88dzH6b6bc8739yxfeGNWxqORFI/9LwaKiJWAr9F\ndf2mbwKfAR4HPkx11PGP5jJASVL/dV0sIuIPgfcA+4FNwKcy83tt798L7JvzCCVJfdfLkcVLgXdm\n5v2d3szMZyPijE7vSZKGWy/F4t9T3Yjo5yLil4Bj2677dKiLA0qShlQvxeLPgA/w4qGmpcBNwFlz\nGdQwe/6DFwMHXsnWiWBJw6yXYnFqZj7U3pCZD0XEa+Y4JjVguqjNZFGT1EkvxWJvRJySmdunGyLi\nFOCJuQ9L/jKXNEh6KRa3AF+KiH9NdUXYXwH+HdUwlCRphPVSLNYBzwJ/SHVjop1UheKz8xCXJGmA\ndF0sMvNnwH8oDwk4+HAZOGQmjZKezuCOiFOp7kvx8vb2zLxlLoNS/xzql7+kI1cvZ3B/Evhd4K95\n8fkWU1TzGZKkEdXLkcVHgDMz89vzFYwkaTD1cqe8/wd4hrYkHYF6ObL4NPCfIuLfMOME5TL5rQb0\nOqfgJLOkudBLsfh8ef5nbW0LqOYsFnbzARGxkOqy5t/LzIsi4iRgM3AcsA24LDOfiYhjqK5s+yaq\nk/7enZk7eohVkjSHehmGOqk8Tm57TG9368PAI23b1wLXZeYKqmtOrSnta4B9mXkKcF3pJ0nqk15u\nq/rdzPwu1cl4z0xvl7ZaEbEUeAfljO+IWACcB9xeumwELimvV5VtyvsrS39JUh90XSwiYlFE/Cnw\nE2B7abs4In6vy4+4HvgdYHp+43jgycx8rmxPAEvK6yVURYny/v7SX5LUB73MWfwR1VDRLwMPl7Zv\nAP8R+NShdoyIi4C9mflARJxbmjsdKUx18V77564F1gJkJq1WqyaFzmZeTnw+9BrbXMV0sJ87iDk3\nZWxsbGBjm41RymeUcoHRyqeXYrESGC93xJsCyMwfRMQJXex7DnBxRFxIdce9V1AdaSyKiLFy9LAU\n2FX6T1Bdf2oiIsaAVwI/nPmhmbkB2FA2pyYnJ3tIp1n9iq2f/00G9f9Hq9Ua2NhmY5TyGaVcYDjy\nGR8f76pfL8ViP9ACdk83RMQ/aN8+mMz8BPCJss+5wL/MzPdFxH8B3kW1Imo1cGfZZUvZ/kZ5/+7M\nPODIQvW8fIekudDLaqibqC5R/lbgqIj4NapJ6D86jJ//ceCjEbGdak7i5tJ+M3B8af8ocPVh/AxJ\n0mHq5cjiWqrJ7c8BR1NdD+qPgfW9/MDMvAe4p7x+DDizQ5+fAJf28rmSpPnTyyXKp6jmGa6fv3Ak\nSYOol6vOnnew9zLz7rkJR5I0iHoZhrp5xvargJdQrVzq5SxuSdKQ6WUY6qT27XKdp08BT811UEcS\nVytJGga9rIZ6kcx8Hvh9qrOyJUkjrKfbqnbwdl64fIcOwSOIFxzsv4WXU5cGVy8T3Dt58SU3foHq\nbOzfnuugJEmDpZcji9+asf33wN9l5o/mMB4dwTzikAZXLxPc/30+A5EkDa5ehqG+QIcrv86Ume8/\nrIgkSQOnl9VQT1LdnGgh1bkVR1HdpOhJ4DttD0nSiOllzuIfAu/IzP8x3RARvw58OjN/c84j09Bz\nBZg0Ono5sjgbuHdG233Ar81dOJKkQdRLsfgW8AcRcSxAef594MH5CEySNDh6KRaXU93xbn9E7KG6\nGdKvU92kSJI0wnpZOrsDeHNELAPGgd2Z+fh8BSZJGhw9Xe4jIo4HzgUWZ+ZnImIcOCozJ+YjOAl6\nnyj3JD5p7nU9DBUR/xh4FHgf8OnSvAK4YR7ikiQNkF7mLK4H3p2Z5wPPlbb76HBbVEnSaOllGGp5\nZm4tr6fP5H6mm8+IiJcCXweOKf1vz8xrIuIkYDNwHLANuCwzn4mIY4BNwJuAJ6iK1I4eYpUkzaFe\njiwejoiZJ9+9DXioi31/CpyXmacBpwPnR8TZwLXAdZm5AtgHrCn91wD7MvMU4LrST5LUJ70Ui48B\nt0bERuDYiPhj4PPAv6rbMTOnMvPHZfPo8pgCzgNuL+0bqS4nAtVlRDaW17cDKyNiQQ+xSpLmUNfF\nIjPvBX4V+FvgFuD/Amdm5v3d7B8RCyPiQWAv8FWq60g9mZnT8x8TwJLyegmws/zc56jO6Ti+21gl\nSXOrqzmLcr/trcBvZuZnZvODym1YT4+IRcAdwGs7dJueC+l0FHHAFW8jYi2wtnw+rVZrNqGxZ1Z7\naVDVfQ/GxsZm/V0ZRKOUzyjlAqOVT1fFIjOfL5PRs75nd9tnPRkR91Bda2pRRIyVo4elwK7SbQJY\nBkxExBjwSuCHHT5rA7ChbE5NTk4ebngaAXXfg1arVdtnmIxSPqOUCwxHPuPj413162U11L8FboiI\na6h+mf/8L/3MPOR9uCPiVcCzpVAcSzUxfi3wNeBdVCuiVgN3ll22lO1vlPfvzszae2lIkuZHL0cK\nNwHvp5qreAZ4lup8i2e72Hcx8LWI+DZwP/DVzPxz4OPARyNiO9WcxM2l/83A8aX9o8DVPcQpSZpj\n3Zwj8erM/D5w0mx/SGZ+G3hDh/bH6HBSX2b+BLh0tj9PkjS3uhmG+jvgFZn5XYCI+HJm/pP5DUuS\nNEi6GYaauTLp3HmIQ5I0wLopFk4sS9IRrpthqLGIeCsvHGHM3CYz756P4CRJg6GbYrGX6oztaU/M\n2J4CTp7LoCRJg6W2WGTm8gbikCQNsMM+I1uSNPp6uq2qNAzqbsM681pg3oZVqueRhSSplsVCklTL\nYiFJqmWxkCTVslhIkmq5GkpHvIOtnnKVlPQCjywkSbUsFpKkWhYLSVIti4UkqZbFQpJUy2IhSarV\nyNLZiFgGbAJeDfwM2JCZ6yPiOOA2YDmwA4jM3BcRC4D1wIXA08DlmbmtiVglSQdq6sjiOeBjmfla\n4Gzgyoh4HXA1sDUzVwBbyzbABcCK8lgL3NBQnJKkDhopFpm5e/rIIDOfAh4BlgCrgI2l20bgkvJ6\nFbApM6cy815gUUQsbiJWSdKBGp+ziIjlwBuA+4ATM3M3VAUFOKF0WwLsbNttorRJkvqg0ct9RMTL\ngS8BH8nMH0XEwbou6NA21eHz1lINU5GZtFqtWcU182Y4Ehz8MiAn3vE/G47k0MbGxmb93R80o5QL\njFY+jRWLiDiaqlDcmplfLs17ImJxZu4uw0x7S/sEsKxt96XArpmfmZkbgA1lc2pycnJ+gpfaDNr3\nrNVqDVxMszVKucBw5DM+Pt5Vv6ZWQy0AbgYeyczPtr21BVgNrCvPd7a1XxURm4GzgP3Tw1WSpOY1\ndWRxDnAZ8FBEPFjaPklVJDIi1gCPA5eW9+6iWja7nWrp7BUNxSlJ6qCRYpGZf0XneQiAlR36TwFX\nzmtQkqSueQa3JKmWxUKSVMtiIUmqZbGQJNWyWEiSalksJEm1LBaSpFqNXhtKGgUHu2bUwhu3NByJ\n1ByLhTTPDlZcwAKj4eEwlCSplsVCklTLYiFJqmWxkCTVslhIkmpZLCRJtVw6K82RQy2RlYadRxaS\npFoWC0lSLYuFJKmWxUKSVKuRCe6IuAW4CNibma8vbccBtwHLgR1AZOa+iFgArAcuBJ4GLs/MbU3E\nKUnqrKnVUJ8H/jOwqa3tamBrZq6LiKvL9seBC4AV5XEWcEN5lkaOV7DVsGhkGCozvw78cEbzKmBj\neb0RuKStfVNmTmXmvcCiiFjcRJySpM76eZ7FiZm5GyAzd0fECaV9CbCzrd9Eads98wMiYi2wtnwG\nrVZrVoHsmdVe0vzp5bs8NjY26+/+oBmlXGC08hnEk/IWdGib6tQxMzcAG6b7TE5OzltQUpP2vPPN\nHds7DU+1Wi1G5bs/SrnAcOQzPj7eVb9+robaMz28VJ73lvYJYFlbv6XAroZjkyS16eeRxRZgNbCu\nPN/Z1n5VRGymmtjePz1cJUnqj6aWzn4ROBdoRcQEcA1VkciIWAM8Dlxaut9FtWx2O9XS2SuaiFGS\ndHCNFIvMfO9B3lrZoe8UcOX8RiRJ6sUgTnBLOohO52XswfMyNP+83IckqZbFQpJUy2IhSaplsZAk\n1bJYSJJqWSwkSbUsFpKkWhYLSVIti4UkqZbFQpJUy2IhSaplsZAk1bJYSJJqWSwkSbUsFpKkWhYL\nSVIti4UkqZbFQpJUa2BvqxoR5wPrgYXATZm5rs8hSdIRayCPLCJiIfA54ALgdcB7I+J1/Y1Kko5c\nA1ksgDOB7Zn5WGY+A2wGVvU5Jkk6Yg3qMNQSYGfb9gRwVp9ikTQCnv/gxR3bF964peFIhtOgFosF\nHdqmZjZExFpgLUBmMj4+Pruf9hffnN1+kubcrP8d1+nTv/N5y6dhgzoMNQEsa9teCuya2SkzN2Tm\nGZl5BlWBGZhHRDzQ7xjMZ/RzGbV8RimXIcun1qAeWdwPrIiIk4DvAe8B/ml/Q5KkI9dAHllk5nPA\nVcB/Ax6pmvJv+xuVJB25BvXIgsy8C7ir33Echg39DmCOjVI+o5QLjFY+o5QLjFA+C6amDpg3liTp\nRQZyGEqSNFgGdhhq0EXELcBFwN7MfH1pOw64DVgO7AAiM/dFxAKqS5dcCDwNXJ6Z2/oRdycRsQzY\nBLwa+BmwITPXD2M+EfFS4OvAMVTf79sz85qyWGIzcBywDbgsM5+JiGOocn8T8ATw7szc0ZfgD6Fc\n1eCbwPcy86JhzicidgBPAc8Dz2XmGcP4XQOIiEXATcDrqZb3fwB4lCHMpY5HFrP3eeD8GW1XA1sz\ncwWwtWxDddmSFeWxFrihoRi79Rzwscx8LXA2cGW5vMow5vNT4LzMPA04HTg/Is4GrgWuK7nsA9aU\n/muAfZl5CnBd6TeIPky12GPasOfz1sw8vSx7h+H8rkH1y/8rmfka4DSq/0fDmsshWSxmKTO/Dvxw\nRvMqYGN5vRG4pK19U2ZOZea9wKKIWNxMpPUyc/f0XziZ+RTVF34JQ5hPienHZfPo8pgCzgNuL+0z\nc5nO8XZgZfkLcGBExFLgHVR/wVLiG9p8DmLovmsR8QrgLcDNAJn5TGY+yRDm0g2Lxdw6MTN3Q/UL\nGDihtHe6fMmShmPrSkQsB94A3MeQ5hMRCyPiQWAv8FXgO8CTZUk2vDjen+dS3t8PHN9sxLWuB36H\naogQqviGOZ8p4C8j4oFyFQYYzu/aycAPgD+JiG9FxE0R8TKGM5daFotmdPrLbuCWoUXEy4EvAR/J\nzB8doutA55OZz2fm6VRn/p8JvLZDt+l4BzqXiJieF3ugrflQMQ90PsU5mflGqmGZKyPiLYfoO8j5\njAFvBG7IzDcAf88LQ06dDHIutSwWc2vP9GFled5b2ru6fEk/RcTRVIXi1sz8cmke2nwAypDAPVTz\nMIsiYnpBR3u8P8+lvP9KDhxe7KdzgIvLpPBmquGn6xnefMjMXeV5L3AHVUEfxu/aBDCRmfeV7dup\niscw5lLLYjG3tgCry+vVwJ1t7e+PiAVlsnX/9GHqIChj2jcDj2TmZ9veGrp8IuJVZYUKEXEs8Daq\nOZivAe8q3WbmMp3ju4C7M3Ng/trLzE9k5tLMXE512Zu7M/N9DGk+EfGyiPjF6dfAbwB/wxB+1zLz\n+8DOiDi1NK0EHmYIc+mGS2dnKSK+CJwLtCJiArgGWAdkRKwBHgcuLd3volout51qydwVjQd8aOcA\nlwEPlbF+gE8ynPksBjaWpaZHUV0q5s8j4mFgc0T8HvAtyqRkef5CRGyn+gv8Pf0IehY+znDmcyJw\nR0RA9fvnTzPzKxFxP8P3XQP4EHBrRLwEeIwqvqMYzlwOyTO4JUm1HIaSJNWyWEiSalksJEm1LBaS\npFoWC0lSLYuFJKmWxUKSVMtiIUmq9f8BWaLXmwOTpRcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "allemp['salary'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variable is highly skewed so we will log transform \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2296c44ac88>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npFoWC0lSLYuFJKmWxUKSVMtiIUmq9f8BWaLXmwOTpRcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Target variable is now more symmetrical than before \n",
    "allemp['salary'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "allemp = allemp.drop( ['degree_level','boss_id', 'level','employee_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "allemp['salary'] = allemp['salary'].apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model 1 - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = allemp\n",
    "from sklearn import linear_model\n",
    "reg=linear_model.LinearRegression()\n",
    "X_2 = df.drop(['salary'], axis = 1)\n",
    "y_2= df.salary\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y_2, test_size=0.2, random_state=101)\n",
    "reg.fit(X_train,y_train)\n",
    "predictions =reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 74.5319839574\n"
     ]
    }
   ],
   "source": [
    "#Transform back to original scale\n",
    "#result = pd.DataFrame({'ytrue': np.exp(y_test),'ypred': np.exp(predictions)})\n",
    "#print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(np.exp(y_test), np.exp(predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model -2 Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = df.drop(['salary'], axis = 1)\n",
    "y_2= df.salary\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y_2, test_size=0.2, random_state=101)\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 78.0065372456\n"
     ]
    }
   ],
   "source": [
    "predictions_2 =rf.predict(X_test)\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(np.exp(y_test), np.exp(predictions_2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning RANDOM Foreset Model \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 300, num = 4)]\n",
    "# Number of features to consider at every split\n",
    "#max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 50, num = 5)]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "#bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth, 'min_samples_split': min_samples_split}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   22.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [50, 133, 216, 300], 'max_depth': [5, 16, 27, 38, 50], 'min_samples_split': [2, 5, 10]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make model with tuned parameter\n",
    "X_3 = df.drop(['salary'], axis = 1)\n",
    "y_3= df.salary\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_3, y_3, test_size=0.2, random_state=101)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor( max_depth=  params['max_depth'],n_estimators= params['n_estimators'])\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                    score\n",
      "dept_HR           0.882239\n",
      "dept_engineering  0.0811734\n",
      "n_subordinates    0.0195001\n",
      "yrs_experience    0.00982653\n",
      "level_num         0.00247826\n",
      "degree_num        0.00200668\n",
      "signing_bonus     0.00104244\n",
      "sex_F             0.000623532\n",
      "dept_marketing    0.000494397\n",
      "sex_M             0.000414325\n",
      "dept_sales        0.000200911\n"
     ]
    }
   ],
   "source": [
    "#Best features \n",
    "from tabulate import tabulate\n",
    "headers = [\"name\", \"score\"]\n",
    "values = sorted(zip(X_train.columns, rf.feature_importances_), key=lambda x: x[1] * -1)\n",
    "print(tabulate(values, headers, tablefmt=\"plain\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.39662023856027206\n"
     ]
    }
   ],
   "source": [
    "predictions_2 =rf.predict(X_test)\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#base case error without tuning \n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "params = {'n_estimators': 500, 'max_depth': 6,\n",
    "        'learning_rate': 0.1, 'loss': 'huber','alpha':0.95}\n",
    "clf = GradientBoostingRegressor(**params).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41812879505370087"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test,clf.predict(X_test)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.42597, std: 0.01504, params: {'learning_rate': 0.15, 'n_estimators': 100},\n",
       "  mean: 0.41688, std: 0.01577, params: {'learning_rate': 0.15, 'n_estimators': 250},\n",
       "  mean: 0.40564, std: 0.01480, params: {'learning_rate': 0.15, 'n_estimators': 500},\n",
       "  mean: 0.39859, std: 0.01498, params: {'learning_rate': 0.15, 'n_estimators': 750},\n",
       "  mean: 0.42942, std: 0.01357, params: {'learning_rate': 0.1, 'n_estimators': 100},\n",
       "  mean: 0.42126, std: 0.01547, params: {'learning_rate': 0.1, 'n_estimators': 250},\n",
       "  mean: 0.41348, std: 0.01553, params: {'learning_rate': 0.1, 'n_estimators': 500},\n",
       "  mean: 0.40593, std: 0.01516, params: {'learning_rate': 0.1, 'n_estimators': 750},\n",
       "  mean: 0.43300, std: 0.01431, params: {'learning_rate': 0.05, 'n_estimators': 100},\n",
       "  mean: 0.42831, std: 0.01438, params: {'learning_rate': 0.05, 'n_estimators': 250},\n",
       "  mean: 0.42244, std: 0.01533, params: {'learning_rate': 0.05, 'n_estimators': 500},\n",
       "  mean: 0.41823, std: 0.01561, params: {'learning_rate': 0.05, 'n_estimators': 750},\n",
       "  mean: 0.35209, std: 0.00872, params: {'learning_rate': 0.01, 'n_estimators': 100},\n",
       "  mean: 0.42717, std: 0.01302, params: {'learning_rate': 0.01, 'n_estimators': 250},\n",
       "  mean: 0.43285, std: 0.01394, params: {'learning_rate': 0.01, 'n_estimators': 500},\n",
       "  mean: 0.43176, std: 0.01387, params: {'learning_rate': 0.01, 'n_estimators': 750}],\n",
       " {'learning_rate': 0.05, 'n_estimators': 100},\n",
       " 0.43299620016452944)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameter tuning \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "p_test3 = {'learning_rate':[0.15,0.1,0.05,0.01], 'n_estimators':[100,250,500,750]}\n",
    "\n",
    "tuning = GridSearchCV(estimator =GradientBoostingRegressor(max_depth=4, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10), \n",
    "            param_grid = p_test3, scoring='explained_variance',n_jobs=4,iid=False, cv=5)\n",
    "tuning.fit(X_train,y_train)\n",
    "tuning.grid_scores_, tuning.best_params_, tuning.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.43148, std: 0.01380, params: {'max_depth': 2},\n",
       "  mean: 0.43355, std: 0.01402, params: {'max_depth': 3},\n",
       "  mean: 0.43273, std: 0.01392, params: {'max_depth': 4},\n",
       "  mean: 0.43112, std: 0.01342, params: {'max_depth': 5},\n",
       "  mean: 0.42781, std: 0.01330, params: {'max_depth': 6},\n",
       "  mean: 0.42313, std: 0.01352, params: {'max_depth': 7}],\n",
       " {'max_depth': 3},\n",
       " 0.43355478065908626)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input parameter from previous chunk - learning rate and n_estimators\n",
    "p_test2 = {'max_depth':[2,3,4,5,6,7] }\n",
    "tuning = GridSearchCV(estimator =GradientBoostingRegressor(learning_rate=0.01,n_estimators=500,max_features='sqrt'), \n",
    "            param_grid = p_test2, scoring='explained_variance',n_jobs=4,iid=False, cv=5)\n",
    "tuning.fit(X_train,y_train)\n",
    "tuning.grid_scores_, tuning.best_params_, tuning.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40062447277350932"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation on test set \n",
    "#input max depth optimal value from previous chunk which is 2 \n",
    "model1 = GradientBoostingRegressor(learning_rate=0.05, n_estimators=100,max_depth=3)\n",
    "model1.fit(X_train,y_train)\n",
    "rmse2 = np.sqrt(mean_squared_error(y_test,model1.predict(X_test)))\n",
    "rmse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                   score\n",
      "dept_HR           0.600466\n",
      "n_subordinates    0.125886\n",
      "yrs_experience    0.105513\n",
      "dept_engineering  0.0540501\n",
      "degree_num        0.0455583\n",
      "signing_bonus     0.0236829\n",
      "dept_marketing    0.0211529\n",
      "level_num         0.00903109\n",
      "sex_F             0.00810402\n",
      "sex_M             0.00406078\n",
      "dept_sales        0.00249488\n"
     ]
    }
   ],
   "source": [
    "#Best features \n",
    "from tabulate import tabulate\n",
    "headers = [\"name\", \"score\"]\n",
    "values = sorted(zip(X_train.columns, model1.feature_importances_), key=lambda x: x[1] * -1)\n",
    "print(tabulate(values, headers, tablefmt=\"plain\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revised Linear Regressor with best features from Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'level'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-857776e95f20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'level'"
     ]
    }
   ],
   "source": [
    "X_train.level.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
